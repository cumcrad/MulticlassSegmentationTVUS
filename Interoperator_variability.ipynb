{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary packages:\n",
    "import os\n",
    "from glob import glob\n",
    "#from pre_processing_IOV import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import my_transforms\n",
    "import torchvision.transforms.functional as F\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import monai\n",
    "from monai.metrics import DiceMetric\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from statsmodels.stats.inter_rater import fleiss_kappa\n",
    "import cv2\n",
    "import InterOperator_utils\n",
    "import pre_processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Load model and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1 is running: Access images from file paths\n",
      "No path provided for input images, check if this path is correct: /home/obsegment/code/ResearchDataset/CLEAR/data/20220625\n",
      "Starting paths have been saved.\n",
      "there are 250 images in the starting directory\n",
      "there are 246 GT segmentations in the majority starting directory\n",
      "there are 250 segmentations in the KJ starting directory\n",
      "there are 248 segmentations in the DC starting directory\n",
      "there are 246 segmentations in the MH starting directory\n"
     ]
    }
   ],
   "source": [
    "#set data loading parameters:\n",
    "use_AMF_images = False\n",
    "use_Inpaint_images = False \n",
    "\n",
    "#determine whether to preprocess the data:\n",
    "apply_AMF_flag = False\n",
    "\n",
    "#set model parameters:\n",
    "rand_state = 42 #random state for the train/test split\n",
    "training_channels = 1\n",
    "batch_size= 16\n",
    "augmentation_flag = False\n",
    "n_classes = 5\n",
    "aug_params = {\n",
    "    'RandAdjustContrastd' : {'prob':1.0, 'gamma':(0.5, 2.5), 'allow_missing_keys':False},\n",
    "    'GaussianSmoothd' : {'sigma' : 1},\n",
    "    'CustomGaussianNoised': {},\n",
    "    'Rotated_180': {'angle': np.pi, 'mode': [\"bilinear\", \"nearest\"]},\n",
    "    'CenterSpatialCropd_200': {'roi_size': (200,200)},\n",
    "    'RandZoomd': {'prob': 1, 'min_zoom': 0.8, 'max_zoom': 0.9, 'mode': [\"area\", \"nearest\"]},\n",
    "}\n",
    "aug_transformations = my_transforms.make_aug_transform(aug_params)\n",
    "n_aug_transformations = len(list(aug_transformations))\n",
    "dice_metric = DiceMetric(include_background=True, reduction=\"mean\") #to_onehot = True or False\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------------------------------- #\n",
    "# STEP 0:\n",
    "# ---------------------------------------------------------------------------------------------------------------------------- #\n",
    "print('Step 1 is running: Access images from file paths')\n",
    "# ---------------------------------------------------------------------------------------------------------------------------- #\n",
    "# Access images from file paths:\n",
    "# ---------------------------------------------------------------------------------------------------------------------------- #\n",
    "\n",
    "#define folder where images are stored:\n",
    "date_labelbox_pull = '20220625' #image folder named by pull date - if not pulling data from labelbox in this run\n",
    "CLEAR_root_path = '/home/obsegment/code/ResearchDataset/CLEAR'\n",
    "raw_img_path = os.path.join(CLEAR_root_path, 'data')\n",
    "results_folder = os.path.join(CLEAR_root_path, 'Results')\n",
    "   \n",
    "\n",
    "data_path = None\n",
    "if use_AMF_images:\n",
    "    start_AMF_path = os.path.join(raw_img_path, date_labelbox_pull)\n",
    "    data_path = start_AMF_path\n",
    "    img_prefix = '*AMF_*'\n",
    "elif use_Inpaint_images:\n",
    "    start_inpaint_path = os.path.join(raw_img_path, date_labelbox_pull)\n",
    "    data_path = start_inpaint_path\n",
    "    img_prefix = '*Inpaint_*'\n",
    "else:\n",
    "    img_prefix = 'CLEAR_g[0-9]_im*' #look for this expression only in the beginning of the path\n",
    "    data_path = os.path.join(raw_img_path, date_labelbox_pull)\n",
    "    print('No path provided for input images, check if this path is correct: ' + data_path)\n",
    "\n",
    "print(\"Starting paths have been saved.\")\n",
    "\n",
    "#generate list of images and segmentations for each expert:\n",
    "images = sorted(glob(os.path.join(data_path, img_prefix))) #list of image paths\n",
    "KJ_segs = sorted(glob(os.path.join(data_path, \"*lab[0-9][0-9][0-9]_KJ*\"))) #list of mask png file paths for expert KJ\n",
    "DC_segs = sorted(glob(os.path.join(data_path, \"*lab[0-9][0-9][0-9]_DC*\"))) #list of mask png file paths for expert DC\n",
    "MH_segs = sorted(glob(os.path.join(data_path, \"*lab[0-9][0-9][0-9]_MH*\"))) #list of mask png file paths for expert MH\n",
    "maj_segs = sorted(glob(os.path.join(data_path, \"*lab[0-9][0-9][0-9]_majGT*\"))) #list of mask file paths for ground truth majority vote\n",
    "\n",
    "#print the number of items in each image and segmentation list - they may be different lengths:\n",
    "print(\"there are {} images in the starting directory\".format(len(images)))\n",
    "print(\"there are {} GT segmentations in the majority starting directory\".format(len(maj_segs)))\n",
    "print(\"there are {} segmentations in the KJ starting directory\".format(len(KJ_segs)))\n",
    "print(\"there are {} segmentations in the DC starting directory\".format(len(DC_segs)))\n",
    "print(\"there are {} segmentations in the MH starting directory\".format(len(MH_segs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Only include images that have been labeled by each expert\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of image_id_list is 246\n",
      "length of KJ segmentation list  is 246\n",
      "length of DC segmentation list  is 246\n",
      "length of MH segmentation list  is 246\n",
      "length of segmentation list  is 246\n",
      "/home/obsegment/code/ResearchDataset/CLEAR/data/20220625/CLEAR_g6_im015.png\n",
      "/home/obsegment/code/ResearchDataset/CLEAR/data/20220625/CLEAR_g6_lab015_KJ.png\n",
      "/home/obsegment/code/ResearchDataset/CLEAR/data/20220625/CLEAR_g6_lab015_DC.png\n",
      "/home/obsegment/code/ResearchDataset/CLEAR/data/20220625/CLEAR_g6_lab015_MH.png\n"
     ]
    }
   ],
   "source": [
    "#create empty lists to fill with image and label IDs for each expert\n",
    "image_id_list = []\n",
    "expert_seg_id_lists = [[], [], []]\n",
    "\n",
    "#from list of image path, get image ID, and generate label ID list for each expert:\n",
    "#only add image/segmentation to ID list if corresponding label_id exists in list of majority GT segmentations\n",
    "for s, seg in enumerate(maj_segs):\n",
    "    for i, img in enumerate(images):\n",
    "        image_id = img.split('/')[-1].split('.')[0] #take everything before .png and after the folder path\n",
    "        label_id = image_id.replace('im', 'lab')\n",
    "        if use_Inpaint_images:\n",
    "            label_id = label_id.replace(\"Inpaint_\", \"\")\n",
    "        if label_id in seg:\n",
    "            image_id_list.append(img)\n",
    "            \n",
    "    for i, expert_segs in enumerate([KJ_segs, DC_segs, MH_segs]):\n",
    "        for idx, lab in enumerate(expert_segs):\n",
    "            i_label_id = lab.split('/')[-1].split('.')[0]\n",
    "            i_label_id = i_label_id.replace('KJ', '').replace('MH', '').replace('DC', '')\n",
    "            if i_label_id in seg:\n",
    "                expert_seg_id_lists[i].append(lab)\n",
    "                \n",
    "KJ_seg_id_list = expert_seg_id_lists[0]\n",
    "DC_seg_id_list = expert_seg_id_lists[1]\n",
    "MH_seg_id_list = expert_seg_id_lists[2]      \n",
    "\n",
    "\n",
    "#print the number of items in each image and segmentation list - check that all lists have same length:      \n",
    "print(\"length of image_id_list is {}\".format(len(image_id_list)))\n",
    "print(\"length of KJ segmentation list  is {}\".format(len(KJ_seg_id_list)))\n",
    "print(\"length of DC segmentation list  is {}\".format(len(DC_seg_id_list)))\n",
    "print(\"length of MH segmentation list  is {}\".format(len(MH_seg_id_list)))\n",
    "print(\"length of segmentation list  is {}\".format(len(maj_segs)))\n",
    "\n",
    "#display the path for one index to verify that the naming conventions align:\n",
    "verify_index = 12\n",
    "print(image_id_list[verify_index])\n",
    "print(KJ_seg_id_list[verify_index])\n",
    "print(DC_seg_id_list[verify_index])\n",
    "print(MH_seg_id_list[verify_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Separate images and segmentations based on quality score (g6, g8, g9) & load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create empty image and segmentation lists for each grade:\n",
    "g6_images, g8_images, g9_images = ([] for i in range(3))\n",
    "g6_maj_segs, g8_maj_segs, g9_maj_segs = ([] for i in range(3))\n",
    "g6_KJ_segs, g8_KJ_segs, g9_KJ_segs = ([] for i in range(3))\n",
    "g6_DC_segs, g8_DC_segs, g9_DC_segs = ([] for i in range(3))\n",
    "g6_MH_segs, g8_MH_segs, g9_MH_segs = ([] for i in range(3))\n",
    "\n",
    "#subdivide image and segmentation id lists based on CLEAR grading scores:\n",
    "for idx, seg in enumerate(maj_segs):\n",
    "    if 'g6' in seg:           \n",
    "        g6_images.append(image_id_list[idx])\n",
    "        g6_maj_segs.append(maj_segs[idx])\n",
    "        g6_KJ_segs.append(KJ_seg_id_list[idx])\n",
    "        g6_DC_segs.append(DC_seg_id_list[idx])\n",
    "        g6_MH_segs.append(MH_seg_id_list[idx])\n",
    "    elif 'g8' in seg:\n",
    "        g8_images.append(image_id_list[idx])\n",
    "        g8_maj_segs.append(maj_segs[idx])\n",
    "        g8_KJ_segs.append(KJ_seg_id_list[idx])\n",
    "        g8_DC_segs.append(DC_seg_id_list[idx])\n",
    "        g8_MH_segs.append(MH_seg_id_list[idx])\n",
    "    elif 'g9' in seg:\n",
    "        g9_images.append(image_id_list[idx])\n",
    "        g9_maj_segs.append(maj_segs[idx])\n",
    "        g9_KJ_segs.append(KJ_seg_id_list[idx])\n",
    "        g9_DC_segs.append(DC_seg_id_list[idx])\n",
    "        g9_MH_segs.append(MH_seg_id_list[idx])\n",
    "\n",
    "#create 3 groupings of data paths, before splitting data set:\n",
    "g6_data_paths = [{\"image\": img, \"label\": {\"KJ\": KJ_seg, \"DC\": DC_seg, \"MH\": MH_seg, \"maj\": maj_seg}} for img, KJ_seg, DC_seg, MH_seg, maj_seg in zip(g6_images, g6_KJ_segs, g6_DC_segs, g6_MH_segs, g6_maj_segs)] \n",
    "g8_data_paths = [{\"image\": img, \"label\": {\"KJ\": KJ_seg, \"DC\": DC_seg, \"MH\": MH_seg, \"maj\": maj_seg}} for img, KJ_seg, DC_seg, MH_seg, maj_seg in zip(g8_images, g8_KJ_segs, g8_DC_segs, g8_MH_segs, g8_maj_segs)] \n",
    "g9_data_paths = [{\"image\": img, \"label\": {\"KJ\": KJ_seg, \"DC\": DC_seg, \"MH\": MH_seg, \"maj\": maj_seg}} for img, KJ_seg, DC_seg, MH_seg, maj_seg in zip(g9_images, g9_KJ_segs, g9_DC_segs, g9_MH_segs, g9_maj_segs)] \n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------------------------------- #\n",
    "# Open image/labels as numpy arrays, convert label to class value     \n",
    "# ---------------------------------------------------------------------------------------------------------------------------- #\n",
    "#load numpy arrays from image/segmentation paths\n",
    "g6_np_data_files = InterOperator_utils.convert_paths_to_np_preserveFileName(g6_data_paths, training_channels)\n",
    "g8_np_data_files = InterOperator_utils.convert_paths_to_np_preserveFileName(g8_data_paths, training_channels)\n",
    "g9_np_data_files = InterOperator_utils.convert_paths_to_np_preserveFileName(g9_data_paths, training_channels)\n",
    "\n",
    "# Pre-process images - this function expects numpy inputs\n",
    "g6_class_json_dict = InterOperator_utils.ToClass_fnc_preserveFileName(g6_np_data_files)\n",
    "g8_class_json_dict = InterOperator_utils.ToClass_fnc_preserveFileName(g8_np_data_files)\n",
    "g9_class_json_dict = InterOperator_utils.ToClass_fnc_preserveFileName(g9_np_data_files)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The above section takes roughly 30 minutes to run.\n",
    "\n",
    "### Step 4: Split data into train/validation/test sets\n",
    "##### This is done in a way that preserves the proportions of g6, g8, and g9 data in the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data into train and validation files:\n",
    "g6_train_files, g6_tmp_files = train_test_split(g6_class_json_dict, test_size = 0.3, random_state = rand_state)\n",
    "g8_train_files, g8_tmp_files = train_test_split(g8_class_json_dict, test_size = 0.3, random_state = rand_state)\n",
    "g9_train_files, g9_tmp_files = train_test_split(g9_class_json_dict, test_size = 0.3, random_state = rand_state)\n",
    "#further split the validation set into validation and test data:\n",
    "g6_val_files, g6_test_files = train_test_split(g6_tmp_files, test_size = 0.33, random_state = rand_state)\n",
    "g8_val_files, g8_test_files = train_test_split(g8_tmp_files, test_size = 0.33, random_state = rand_state)\n",
    "g9_val_files, g9_test_files = train_test_split(g9_tmp_files, test_size = 0.33, random_state = rand_state)\n",
    "#combine lists for each group: train, validation and test:\n",
    "train_files = g6_train_files + g8_train_files + g9_train_files\n",
    "val_files = g6_val_files + g8_val_files + g9_val_files\n",
    "test_files = g6_test_files + g8_test_files + g9_test_files\n",
    "#create list of all files in the dataset:\n",
    "all_files = train_files + val_files + test_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 5: Extract file names for each dataset. Preserve only image and label dictionary keys when loading the data for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 246 files in total\n",
      "n_train_files = 171\n",
      "n_val_files = 49\n",
      "n_test_files = 26\n",
      "The training set is 70 percent of the dataset, the validation set is 20 percent of the dataset and the test set is 11 percent of the test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████| 85/85 [00:00<00:00, 239.94it/s]\n",
      "Loading dataset: 100%|██████████| 49/49 [00:00<00:00, 298.89it/s]\n",
      "Loading dataset: 100%|██████████| 26/26 [00:00<00:00, 253.64it/s]\n",
      "Loading dataset: 100%|██████████| 85/85 [00:00<00:00, 223.65it/s]\n",
      "Loading dataset: 100%|██████████| 49/49 [00:00<00:00, 190.05it/s]\n",
      "Loading dataset: 100%|██████████| 26/26 [00:00<00:00, 279.77it/s]\n",
      "Loading dataset: 100%|██████████| 85/85 [00:00<00:00, 255.78it/s]\n",
      "Loading dataset: 100%|██████████| 49/49 [00:00<00:00, 218.78it/s]\n",
      "Loading dataset: 100%|██████████| 26/26 [00:00<00:00, 293.82it/s]\n",
      "Loading dataset: 100%|██████████| 85/85 [00:00<00:00, 293.23it/s]\n",
      "Loading dataset: 100%|██████████| 49/49 [00:00<00:00, 269.01it/s]\n",
      "Loading dataset: 100%|██████████| 26/26 [00:00<00:00, 185.89it/s]\n",
      "Loading dataset: 100%|██████████| 246/246 [00:00<00:00, 269.00it/s]\n",
      "Loading dataset: 100%|██████████| 246/246 [00:00<00:00, 248.85it/s]\n",
      "Loading dataset: 100%|██████████| 246/246 [00:01<00:00, 243.10it/s]\n",
      "Loading dataset: 100%|██████████| 246/246 [00:01<00:00, 239.52it/s]\n"
     ]
    }
   ],
   "source": [
    "#Extract file names for all files:\n",
    "all_filenames = []\n",
    "KJ_all_files_data = []\n",
    "DC_all_files_data = []\n",
    "MH_all_files_data = []\n",
    "maj_all_files_data = []\n",
    "\n",
    "#Create dictionary of image and labels only, separate filenames into list:\n",
    "for dict in all_files:\n",
    "    all_filenames.append(dict[\"filename\"])\n",
    "    KJ_all_files_data.append({\"image\": dict[\"image\"], \"label\": dict[\"label\"][\"KJ\"]})\n",
    "    DC_all_files_data.append({\"image\": dict[\"image\"], \"label\": dict[\"label\"][\"DC\"]})\n",
    "    MH_all_files_data.append({\"image\": dict[\"image\"], \"label\": dict[\"label\"][\"MH\"]})\n",
    "    maj_all_files_data.append({\"image\": dict[\"image\"], \"label\": dict[\"label\"][\"maj\"]})\n",
    "\n",
    "#Extract file names for train files:\n",
    "train_filenames = []\n",
    "KJ_train_files_data = []\n",
    "DC_train_files_data = []\n",
    "MH_train_files_data = []\n",
    "maj_train_files_data = []\n",
    "for dict in train_files:\n",
    "    train_filenames.append(dict[\"filename\"])\n",
    "    KJ_train_files_data.append({\"image\": dict[\"image\"], \"label\": dict[\"label\"][\"KJ\"]})\n",
    "    DC_train_files_data.append({\"image\": dict[\"image\"], \"label\": dict[\"label\"][\"DC\"]})\n",
    "    MH_train_files_data.append({\"image\": dict[\"image\"], \"label\": dict[\"label\"][\"MH\"]})\n",
    "    maj_train_files_data.append({\"image\": dict[\"image\"], \"label\": dict[\"label\"][\"maj\"]})\n",
    "\n",
    "#Extract file names for validation files:\n",
    "val_filenames = []\n",
    "val_files_data = []\n",
    "KJ_val_files_data = []\n",
    "DC_val_files_data = []\n",
    "MH_val_files_data = []\n",
    "maj_val_files_data = []\n",
    "for dict in val_files:\n",
    "    val_filenames.append(dict[\"filename\"])\n",
    "    KJ_val_files_data.append({\"image\": dict[\"image\"], \"label\": dict[\"label\"][\"KJ\"]})\n",
    "    DC_val_files_data.append({\"image\": dict[\"image\"], \"label\": dict[\"label\"][\"DC\"]})\n",
    "    MH_val_files_data.append({\"image\": dict[\"image\"], \"label\": dict[\"label\"][\"MH\"]})\n",
    "    maj_val_files_data.append({\"image\": dict[\"image\"], \"label\": dict[\"label\"][\"maj\"]})\n",
    "\n",
    "#Extract file names for test files:\n",
    "test_filenames = []\n",
    "test_files_data = []\n",
    "KJ_test_files_data = []\n",
    "DC_test_files_data = []\n",
    "MH_test_files_data = []\n",
    "maj_test_files_data = []\n",
    "for dict in test_files:\n",
    "    test_filenames.append(dict[\"filename\"])\n",
    "    test_files_data.append({\"image\": dict[\"image\"], \"label\": dict[\"label\"]})\n",
    "    KJ_test_files_data.append({\"image\": dict[\"image\"], \"label\": dict[\"label\"][\"KJ\"]})\n",
    "    DC_test_files_data.append({\"image\": dict[\"image\"], \"label\": dict[\"label\"][\"DC\"]})\n",
    "    MH_test_files_data.append({\"image\": dict[\"image\"], \"label\": dict[\"label\"][\"MH\"]})\n",
    "    maj_test_files_data.append({\"image\": dict[\"image\"], \"label\": dict[\"label\"][\"maj\"]})\n",
    "\n",
    "#review composition of train/val/test dataset:\n",
    "n_train_files = len(train_files)\n",
    "n_val_files = len(val_files)\n",
    "n_test_files = len(test_files)\n",
    "n_total_files = n_train_files + n_val_files + n_test_files\n",
    "#double check that the length of all files is the same as n_total_files\n",
    "if n_total_files == len(all_files):\n",
    "    print(\"There are {} files in total\".format(n_total_files))\n",
    "    \n",
    "#print the number of files in each dataset\n",
    "print('n_train_files = ' + str(n_train_files))\n",
    "print('n_val_files = ' + str(n_val_files))\n",
    "print('n_test_files = ' + str(n_test_files))\n",
    "\n",
    "#print the percentage of files in each dataset:\n",
    "percent_train = int(np.round(n_train_files/n_total_files*100,0))\n",
    "percent_val = int(np.round(n_val_files/n_total_files*100,0))\n",
    "percent_test = int(np.round(n_test_files/n_total_files*100,0))\n",
    "print(\"The training set is {} percent of the dataset, the validation set is {} percent of the dataset and the test set is {} percent of the test set\".format(percent_train,percent_val,percent_test))\n",
    "\n",
    "#load data from file paths:\n",
    "KJ_train_loader, KJ_val_loader, KJ_test_loader, KJ_train_ds, KJ_val_ds, KJ_test_ds= pre_processing.load_data(KJ_train_files_data, KJ_val_files_data, KJ_test_files_data, batch_size, augmentation_flag, aug_transformations)\n",
    "DC_train_loader, DC_val_loader, DC_test_loader, DC_train_ds, DC_val_ds, DC_test_ds= pre_processing.load_data(DC_train_files_data, DC_val_files_data, DC_test_files_data, batch_size, augmentation_flag, aug_transformations)\n",
    "MH_train_loader, MH_val_loader, MH_test_loader, MH_train_ds, MH_val_ds, MH_test_ds= pre_processing.load_data(MH_train_files_data, MH_val_files_data, MH_test_files_data, batch_size, augmentation_flag, aug_transformations)\n",
    "maj_train_loader, maj_val_loader, maj_test_loader, maj_train_ds, maj_val_ds, maj_test_ds= pre_processing.load_data(maj_train_files_data, maj_val_files_data, maj_test_files_data, batch_size, augmentation_flag, aug_transformations)\n",
    "\n",
    "\n",
    "all_KJ_loader, all_DC_loader, all_MH_loader, all_maj_loader, all_KJ_ds, all_DC_ds, all_MH_ds, all_maj_ds = InterOperator_utils.load_all_data(KJ_all_files_data, DC_all_files_data, MH_all_files_data, maj_all_files_data, batch_size, augmentation_flag, aug_transformations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6: Average Fliess Kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fleiss kappa score for image 0 is 0.7463524233935485\n",
      "fleiss kappa score for image 1 is 0.8688774997015362\n",
      "fleiss kappa score for image 2 is 0.7975156294629788\n",
      "fleiss kappa score for image 3 is 0.8988252137641005\n",
      "fleiss kappa score for image 4 is 0.8702989567003989\n",
      "fleiss kappa score for image 5 is 0.8922317287824635\n",
      "fleiss kappa score for image 6 is 0.8179672693733938\n",
      "fleiss kappa score for image 7 is 0.8284829442763697\n",
      "fleiss kappa score for image 8 is 0.8752571007151269\n",
      "fleiss kappa score for image 9 is 0.8220149590600276\n",
      "fleiss kappa score for image 10 is 0.8708227876374188\n",
      "fleiss kappa score for image 11 is 0.8735126415198144\n",
      "fleiss kappa score for image 12 is 0.8737600899835141\n",
      "fleiss kappa score for image 13 is 0.8991697325033952\n",
      "fleiss kappa score for image 14 is 0.841318091839438\n",
      "fleiss kappa score for image 15 is 0.8263852523177434\n",
      "fleiss kappa score for image 16 is 0.8563459388824668\n",
      "fleiss kappa score for image 17 is 0.908379000076869\n",
      "fleiss kappa score for image 18 is 0.8604817918084163\n",
      "fleiss kappa score for image 19 is 0.8104685522909082\n",
      "fleiss kappa score for image 20 is 0.8897791258846047\n",
      "fleiss kappa score for image 21 is 0.872132337376961\n",
      "fleiss kappa score for image 22 is 0.9025334210527234\n",
      "fleiss kappa score for image 23 is 0.9058569181930989\n",
      "fleiss kappa score for image 24 is 0.8297816551357365\n",
      "fleiss kappa score for image 25 is 0.8790597313903084\n",
      "average fleiss kappa is 0.85836964588936\n"
     ]
    }
   ],
   "source": [
    "avg_fk = InterOperator_utils.fliess_kappa(results_folder, KJ_test_loader, DC_test_loader, MH_test_loader, test_filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 7: Save overlay of segmentations on top of US image, preserving original image size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save overlay for train, validation, and test images\n",
    "InterOperator_utils.save_image_overlay(results_subfolder = results_folder, files = test_files, n_classes = 5)\n",
    "InterOperator_utils.save_image_overlay(results_subfolder = results_folder, files = val_files, n_classes = 5)\n",
    "InterOperator_utils.save_image_overlay(results_subfolder = results_folder, files = train_files, n_classes = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 8: Calculate Dice score, Hausdorff distance, and Jaccard index metrics for experts compared to the majority GT label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "the prediction of class 1 is all 0, this may result in nan/inf distance.\n",
      "the prediction of class 1 is all 0, this may result in nan/inf distance.\n",
      "the prediction of class 1 is all 0, this may result in nan/inf distance.\n",
      "the prediction of class 4 is all 0, this may result in nan/inf distance.\n",
      "the prediction of class 4 is all 0, this may result in nan/inf distance.\n"
     ]
    }
   ],
   "source": [
    "InterOperator_utils.save_CLEAR_IOV_metrics(results_subfolder =results_folder, KJ_test_ds=KJ_test_ds, DC_test_ds=DC_test_ds, MH_test_ds=MH_test_ds, maj_test_ds=maj_test_ds, dice_metric = dice_metric, n_classes= n_classes, test_filenames=test_filenames)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "137f3d8a4a30e1b147cc21fbfe672409ca3da889219f6bf0af90856503c094e7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
